{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"E:\\DEEP LEARNING\\Projects\\House Price Predictions\\train.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(r\"E:\\DEEP LEARNING\\Projects\\House Price Predictions\\test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Predictors and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(labels = ['SalePrice', 'Id'], axis = 1)\n",
    "y = dataset['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Data on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['LotFrontage'].fillna(value = X['LotFrontage'].mean(), inplace=True)\n",
    "X['BsmtQual'].fillna(value = 'Not Available', inplace=True)\n",
    "X['BsmtCond'].fillna(value = 'Not Available', inplace=True)\n",
    "X['BsmtExposure'].fillna(value = 'Not Available', inplace=True)\n",
    "X['BsmtFinType1'].fillna(value = 'Not Available', inplace=True)\n",
    "X['BsmtFinType2'].fillna(value = 'Not Available', inplace=True)\n",
    "X['GarageType'].fillna(value = 'Not Available', inplace=True)\n",
    "X['GarageYrBlt'].fillna(value = 'Not Available', inplace=True)\n",
    "X['GarageFinish'].fillna(value = 'Not Available', inplace=True)\n",
    "X['GarageQual'].fillna(value = 'Not Available', inplace=True)\n",
    "X['GarageCond'].fillna(value = 'Not Available', inplace=True)\n",
    "X['PoolQC'].fillna(value = 'Not Available', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X.columns[X.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop MSSubclass, LotFrontage, LotArea,  Alley, LotShape, LandContour, LotConfig, Condition1, Condition2, 'RoofStyle' ,RoofMatl', 'Exterior1st', 'Exterior2nd', 'Heating', 'HeatingQC', 'CentralAir', '1stFlrSF', '2ndFlrSF',  'LowQualFinSF', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr','Fireplaces', 'FireplaceQu', 'GarageYrBlt', 'GarageFinish', 'GarageArea','WoodDeckSF', 'OpenPorchSF',  'EnclosedPorch', '3SsnPorch', 'ScreenPorch',PoolArea, 'Fence', 'MiscVal','SaleType', 'SaleCondition', 'MasVnrType' , 'MasVnrArea' , 'MiscFeature' , 'Electrical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = X.drop(labels = ['MSSubClass', 'LotFrontage', 'LotArea', 'Alley', 'LotShape', 'LandContour',\n",
    "                                           'LotConfig', 'Condition1', 'Condition2', 'RoofStyle' ,'RoofMatl', 'Exterior1st',\n",
    "                                           'Exterior2nd', 'Heating', 'HeatingQC', 'CentralAir', '1stFlrSF', '2ndFlrSF', \n",
    "                                           'LowQualFinSF', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
    "                                           'BedroomAbvGr', 'KitchenAbvGr','Fireplaces', 'FireplaceQu', 'GarageYrBlt',\n",
    "                                           'GarageFinish', 'GarageArea','WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n",
    "                                           '3SsnPorch', 'ScreenPorch','PoolArea', 'Fence', 'MiscVal','SaleType',\n",
    "                                           'SaleCondition', 'MasVnrType' , 'MasVnrArea' , 'MiscFeature' , 'Electrical'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#heatmap for visuall perception of null values\n",
    "sns.heatmap(X_cleaned.isnull(), cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = test_data.drop(labels = ['Id','MSSubClass', 'LotFrontage', 'LotArea', 'Alley', 'LotShape', 'LandContour',\n",
    "                                           'LotConfig', 'Condition1', 'Condition2', 'RoofStyle' ,'RoofMatl', 'Exterior1st',\n",
    "                                           'Exterior2nd', 'Heating', 'HeatingQC', 'CentralAir', '1stFlrSF', '2ndFlrSF', \n",
    "                                           'LowQualFinSF', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
    "                                           'BedroomAbvGr', 'KitchenAbvGr','Fireplaces', 'FireplaceQu', 'GarageYrBlt',\n",
    "                                           'GarageFinish', 'GarageArea','WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n",
    "                                           '3SsnPorch', 'ScreenPorch','PoolArea', 'Fence', 'MiscVal','SaleType',\n",
    "                                           'SaleCondition', 'MasVnrType' , 'MasVnrArea' , 'MiscFeature' , 'Electrical'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns columns having null values\n",
    "Y[Y.columns[Y.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual perception of null data\n",
    "sns.heatmap(Y.isnull(), cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y['MSZoning'].fillna(value = Y['MSZoning'].mode()[0], inplace=True)\n",
    "Y['Utilities'].fillna(value = Y['Utilities'].mode()[0], inplace=True)\n",
    "Y['BsmtQual'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['BsmtCond'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['BsmtExposure'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['BsmtFinType1'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['BsmtFinSF1'].fillna(value = Y['BsmtFinSF1'].mean(), inplace=True)\n",
    "Y['BsmtFinType2'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['BsmtFinSF2'].fillna(value = Y['BsmtFinSF2'].mean(), inplace=True)\n",
    "Y['BsmtUnfSF'].fillna(value = Y['BsmtUnfSF'].mean(), inplace=True)\n",
    "Y['TotalBsmtSF'].fillna(value = Y['TotalBsmtSF'].mean(), inplace=True)\n",
    "Y['KitchenQual'].fillna(value = Y['KitchenQual'].mode()[0], inplace=True)\n",
    "Y['Functional'].fillna(value = Y['Functional'].mode()[0], inplace=True)\n",
    "Y['GarageType'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['GarageCars'].fillna(value = Y['GarageCars'].mean(), inplace=True)\n",
    "Y['GarageQual'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['GarageCond'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['PoolQC'].fillna(value = 'Not Available', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(Y.isnull(), cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y[Y.columns[Y.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate both dataset row wise to create dummy variables\n",
    "combined_df = pd.concat([X_cleaned, Y], axis=0)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_df = pd.get_dummies(combined_df, drop_first=True, columns=['MSZoning', 'Street', 'Utilities', 'LandSlope', 'Neighborhood',\n",
    "                                                                'BldgType', 'HouseStyle', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
    "                                                                'BsmtCond', 'BsmtExposure', 'BsmtFinType1','BsmtFinType2',\n",
    "                                                                'Functional','KitchenQual', 'GarageType', 'GarageQual',\n",
    "                                                               'GarageCond', 'PavedDrive', 'PoolQC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check any duplicated columns are created\n",
    "combined_df = combined_df.loc[:, ~combined_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split combined data back to respective training and test dataset\n",
    "X_cleaned = combined_df.iloc[:1460,:]\n",
    "Y_encoded = combined_df.iloc[1460:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cleaned = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into Training and Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "Y_encoded = scaler.transform(Y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model_xgb = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "search_parameters = {   'max_depth' : [1,2,3,4,5,6,7,8,9,10,11,12,15],\n",
    "                        'learning_rate' : [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.15, 0.20, 0.25],\n",
    "                        'n_estimators' : [100, 150, 200, 250, 300, 500, 600, 800 ,900, 1000, 1100, 1500],\n",
    "                        'booster' : ['gbtree', 'gblinear'],\n",
    "                        'gamma' : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                        'min_child_weight' : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CV Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "search_cv = RandomizedSearchCV( estimator = model_xgb,\n",
    "                                param_distributions = search_parameters,\n",
    "                                cv = 5,\n",
    "                                n_iter=50,\n",
    "                                scoring='neg_mean_absolute_error',\n",
    "                                n_jobs=4,\n",
    "                                verbose=5,\n",
    "                                random_state=50,\n",
    "                                return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cv.fit(X_train, y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor(    base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                                 colsample_bynode=1, colsample_bytree=1, gamma=9,\n",
    "                                 importance_type='gain', learning_rate=0.05, max_delta_step=0,\n",
    "                                 max_depth=6, min_child_weight=0, missing=None, n_estimators=500,\n",
    "                                 n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "                                 reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "                                 silent=None, subsample=1, verbosity=1\n",
    "                            )\n",
    "\n",
    "regressor.fit(X_train, y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb_preds=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_predictions = regressor.predict(Y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(Test_set_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Submission Dataframe\n",
    "pred = pd.DataFrame(Test_set_predictions)\n",
    "sub_df = pd.read_csv(r\"E:\\DEEP LEARNING\\Projects\\House Price Predictions\\sample_submission.csv\")\n",
    "dataset_submit = pd.concat([sub_df['Id'], pred], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_submit.columns = ['Id','SalePrice']\n",
    "dataset_submit.to_csv('Submission_xgboost_without_corr_mapped.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

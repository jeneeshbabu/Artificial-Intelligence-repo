{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"E:\\DEEP LEARNING\\Projects\\House Price Predictions\\train.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(r\"E:\\DEEP LEARNING\\Projects\\House Price Predictions\\test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Predictors and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(labels = ['SalePrice', 'Id'], axis = 1)\n",
    "y = dataset['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Data on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['LotFrontage'].fillna(value = X['LotFrontage'].mean(), inplace=True)\n",
    "X['BsmtQual'].fillna(value = 'Not Available', inplace=True)\n",
    "X['BsmtCond'].fillna(value = 'Not Available', inplace=True)\n",
    "X['BsmtExposure'].fillna(value = 'Not Available', inplace=True)\n",
    "X['BsmtFinType1'].fillna(value = 'Not Available', inplace=True)\n",
    "X['BsmtFinType2'].fillna(value = 'Not Available', inplace=True)\n",
    "X['GarageType'].fillna(value = 'Not Available', inplace=True)\n",
    "X['GarageYrBlt'].fillna(value = 'Not Available', inplace=True)\n",
    "X['GarageFinish'].fillna(value = 'Not Available', inplace=True)\n",
    "X['GarageQual'].fillna(value = 'Not Available', inplace=True)\n",
    "X['GarageCond'].fillna(value = 'Not Available', inplace=True)\n",
    "X['PoolQC'].fillna(value = 'Not Available', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[X.columns[X.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop MSSubclass, LotFrontage, LotArea,  Alley, LotShape, LandContour, LotConfig, Condition1, Condition2, 'RoofStyle' ,RoofMatl', 'Exterior1st', 'Exterior2nd', 'Heating', 'HeatingQC', 'CentralAir', '1stFlrSF', '2ndFlrSF',  'LowQualFinSF', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr','Fireplaces', 'FireplaceQu', 'GarageYrBlt', 'GarageFinish', 'GarageArea','WoodDeckSF', 'OpenPorchSF',  'EnclosedPorch', '3SsnPorch', 'ScreenPorch',PoolArea, 'Fence', 'MiscVal','SaleType', 'SaleCondition', 'MasVnrType' , 'MasVnrArea' , 'MiscFeature' , 'Electrical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = X.drop(labels = ['MSSubClass', 'LotFrontage', 'LotArea', 'Alley', 'LotShape', 'LandContour',\n",
    "                                           'LotConfig', 'Condition1', 'Condition2', 'RoofStyle' ,'RoofMatl', 'Exterior1st',\n",
    "                                           'Exterior2nd', 'Heating', 'HeatingQC', 'CentralAir', '1stFlrSF', '2ndFlrSF', \n",
    "                                           'LowQualFinSF', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
    "                                           'BedroomAbvGr', 'KitchenAbvGr','Fireplaces', 'FireplaceQu', 'GarageYrBlt',\n",
    "                                           'GarageFinish', 'GarageArea','WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n",
    "                                           '3SsnPorch', 'ScreenPorch','PoolArea', 'Fence', 'MiscVal','SaleType',\n",
    "                                           'SaleCondition', 'MasVnrType' , 'MasVnrArea' , 'MiscFeature' , 'Electrical'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visual Perception of Null Data\n",
    "sns.heatmap(X_cleaned.isnull(), cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = test_data.drop(labels = ['Id','MSSubClass', 'LotFrontage', 'LotArea', 'Alley', 'LotShape', 'LandContour',\n",
    "                                           'LotConfig', 'Condition1', 'Condition2', 'RoofStyle' ,'RoofMatl', 'Exterior1st',\n",
    "                                           'Exterior2nd', 'Heating', 'HeatingQC', 'CentralAir', '1stFlrSF', '2ndFlrSF', \n",
    "                                           'LowQualFinSF', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
    "                                           'BedroomAbvGr', 'KitchenAbvGr','Fireplaces', 'FireplaceQu', 'GarageYrBlt',\n",
    "                                           'GarageFinish', 'GarageArea','WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n",
    "                                           '3SsnPorch', 'ScreenPorch','PoolArea', 'Fence', 'MiscVal','SaleType',\n",
    "                                           'SaleCondition', 'MasVnrType' , 'MasVnrArea' , 'MiscFeature' , 'Electrical'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns columns having null data\n",
    "Y[Y.columns[Y.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(Y.isnull(), cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y['MSZoning'].fillna(value = Y['MSZoning'].mode()[0], inplace=True)\n",
    "Y['Utilities'].fillna(value = Y['Utilities'].mode()[0], inplace=True)\n",
    "Y['BsmtQual'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['BsmtCond'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['BsmtExposure'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['BsmtFinType1'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['BsmtFinSF1'].fillna(value = Y['BsmtFinSF1'].mean(), inplace=True)\n",
    "Y['BsmtFinType2'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['BsmtFinSF2'].fillna(value = Y['BsmtFinSF2'].mean(), inplace=True)\n",
    "Y['BsmtUnfSF'].fillna(value = Y['BsmtUnfSF'].mean(), inplace=True)\n",
    "Y['TotalBsmtSF'].fillna(value = Y['TotalBsmtSF'].mean(), inplace=True)\n",
    "Y['KitchenQual'].fillna(value = Y['KitchenQual'].mode()[0], inplace=True)\n",
    "Y['Functional'].fillna(value = Y['Functional'].mode()[0], inplace=True)\n",
    "Y['GarageType'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['GarageCars'].fillna(value = Y['GarageCars'].mean(), inplace=True)\n",
    "Y['GarageQual'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['GarageCond'].fillna(value = 'Not Available', inplace=True)\n",
    "Y['PoolQC'].fillna(value = 'Not Available', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(Y.isnull(), cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y[Y.columns[Y.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate both dataset row wise to create dummy variables\n",
    "combined_df = pd.concat([X_cleaned, Y], axis=0)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find any Correlation between columns\n",
    "corr_matrix = combined_df.corr().abs()\n",
    "\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find features with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
    "\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_df = pd.get_dummies(combined_df, drop_first=True, columns=['MSZoning', 'Street', 'Utilities', 'LandSlope', 'Neighborhood',\n",
    "                                                                'BldgType', 'HouseStyle', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
    "                                                                'BsmtCond', 'BsmtExposure', 'BsmtFinType1','BsmtFinType2',\n",
    "                                                                'Functional','KitchenQual', 'GarageType', 'GarageQual',\n",
    "                                                               'GarageCond', 'PavedDrive', 'PoolQC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check any duplicated columns are created\n",
    "combined_df = combined_df.loc[:, ~combined_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the combine dataset back to respective training and test dataset\n",
    "X_cleaned = combined_df.iloc[:1460,:]\n",
    "Y_encoded = combined_df.iloc[1460:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cleaned = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into Training and Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "Y_encoded = scaler.transform(Y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCS will reduce the data keeping 95% of the variance\n",
    "from sklearn.decomposition import PCA\n",
    "reducer = PCA(.95)\n",
    "X_train = reducer.fit_transform(X_train)\n",
    "X_test = reducer.transform(X_test)\n",
    "Y_encoded = reducer.transform(Y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, activation = 'relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam', loss = 'mean_squared_error', metrics = ['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x = X_train, y = y_train.to_numpy(), batch_size = 32, epochs = 250, validation_data=(X_test,y_test.to_numpy()), \n",
    "                   callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, y_test, batch_size=10)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for mean_squared_error\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.title('model mean_squared_error')\n",
    "plt.ylabel('mean_squared_error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'dev'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_predictions = model.predict(Y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(Test_set_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_set_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Submission Dataframe\n",
    "pred = pd.DataFrame(Test_set_predictions)\n",
    "sub_df = pd.read_csv(r\"E:\\DEEP LEARNING\\Projects\\House Price Predictions\\sample_submission.csv\")\n",
    "dataset_submit = pd.concat([sub_df['Id'], pred], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_submit.columns = ['Id','SalePrice']\n",
    "dataset_submit.to_csv('Submission_ANN_with_PCA.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
